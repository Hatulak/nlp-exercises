{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "import ssl\n",
    "import spacy\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "from smart_open import smart_open\n",
    "from gensim.downloader import base_dir\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "read_list = []\n",
    "\n",
    "path = os.path.join(base_dir, '20-newsgroups', \"20-newsgroups.gz\")\n",
    "with smart_open(path, 'rb') as infile:\n",
    "    for record in infile:\n",
    "        read_list.append(json.loads(record))\n",
    "\n",
    "df20News = pd.DataFrame.from_records(read_list)\n",
    "\n",
    "sentences_corpus = []\n",
    "\n",
    "for index, row in df20News.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(index)\n",
    "    text = row['data']\n",
    "    doc = nlp(text)  \n",
    "    for sent in doc.sents:\n",
    "        sentences_corpus.append([token.lemma_.lower() for token in sent if not token.is_stop and token.is_alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importujemy moduł, który pozwoli na sprawdzenie liczby rdzeniu CPU\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wielkość wektora wyjściowego\n",
    "embedding_size = 50\n",
    "\n",
    "# Maksymalna odległość między bieżącym a przewidywanym słowem w zdaniu.\n",
    "window_size = 5\n",
    "\n",
    "# Minimalna liczba wystąpień słowa w korpusie, które należy uwzględnić w modelu.\n",
    "# Im wyższa liczba, tym mniej słów mamy w naszym ciele\n",
    "min_word = 1\n",
    "\n",
    "# Model CBOW (0) lub skip-gram (1)\n",
    "sg = 0\n",
    "\n",
    "# Liczba iteracji (epok) uczenia sieci\n",
    "iterations = 2\n",
    "\n",
    "# Ustawienie stałej wartości zapobiega losowości wyników\n",
    "# przy każdorazowym uruchomieniu\n",
    "random_state = 42\n",
    "\n",
    "# 0 negative sampling lub 1 hierarchiczny softmax\n",
    "hs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klasy pomocniczne, które pozwolą na wypisywanie startu/końca\n",
    "# uczenia kolejnej iteracji modelu Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class EpochSaver(CallbackAny2Vec):\n",
    "    \"\"\"Callback to save model after each epoch.\"\"\"\n",
    "    def __init__(self, path_prefix):\n",
    "        self.path_prefix = path_prefix\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        output_path = get_tmpfile(f'{self.path_prefix}_epoch{self.epoch}.model')\n",
    "        \n",
    "        model.save(output_path)\n",
    "\n",
    "        self.epoch += 1\n",
    "\n",
    "\n",
    "class EpochLogger(CallbackAny2Vec):\n",
    "    \"\"\"Callback to log information about training.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "    \n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f\"Epoch #{self.epoch} start\")\n",
    "    \n",
    "    def on_epoch_end(self, model):\n",
    "        # If hs=1 then loss component corresponding to hierarchical softmax\n",
    "        # else loss component corresponding to negative sampling\n",
    "        # loss = model.get_latest_training_loss()\n",
    "\n",
    "        # print(\"Epoch #{} end with loss: {:.2f}\".format(self.epoch, loss))\n",
    "        print(f\"Epoch #{self.epoch} end\")\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n"
     ]
    }
   ],
   "source": [
    "epoch_logger = EpochLogger()\n",
    "\n",
    "# To może potrwać kilka minut\n",
    "model = Word2Vec(\n",
    "    sentences_corpus,\n",
    "    size=embedding_size,\n",
    "    window=window_size,\n",
    "    min_count=min_word,\n",
    "    sg=sg,\n",
    "    iter=iterations,\n",
    "    seed=random_state,\n",
    "    hs=hs,\n",
    "    workers=cores,\n",
    "    callbacks=[epoch_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model-w2v-cbow.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 76172)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set(model.wv.index2word)\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "len(vocabulary) == len(words), len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def average_word_vectors(model: Word2Vec, words: List, vocabulary: set) -> np.array:\n",
    "    \"\"\"\n",
    "    Method return NumPy array as a Average Word Vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    words: list = [word for word in words if word in vocabulary]\n",
    "\n",
    "    if words:\n",
    "        feature_vector: np.array = np.mean(\n",
    "            model.wv[words],\n",
    "            axis=0,\n",
    "            dtype=\"float64\"\n",
    "        )\n",
    "    else:\n",
    "        feature_vector: np.array = np.zeros(\n",
    "            (model.vector_size,),\n",
    "            dtype=\"float64\"\n",
    "        )\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def word_normalization(word: str) -> str:\n",
    "    \"\"\"\n",
    "    Word normalization by removing \"white chars\" and lowering it\n",
    "    \"\"\"\n",
    "    \n",
    "    return word.strip().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09833478,  0.1425009 ,  0.22438635, -0.04965596, -0.20659858,\n",
       "        0.17390585,  0.11089459,  0.16279934, -0.02024491, -0.14275764,\n",
       "       -0.20162317,  0.06024716, -0.16846159, -0.13686574,  0.09437556,\n",
       "        0.11898863,  0.10310286, -0.05074783,  0.30350715,  0.00610311,\n",
       "       -0.19644311, -0.17471276,  0.1977462 , -0.19816767,  0.07887521,\n",
       "       -0.0354114 , -0.0525753 , -0.057479  , -0.29074043,  0.18460892,\n",
       "        0.05378341, -0.1217956 ,  0.21839888,  0.17038597,  0.17741616,\n",
       "        0.05682572,  0.25229126,  0.33775797,  0.12778266,  0.04147685,\n",
       "       -0.0517571 ,  0.17921944, -0.26878074,  0.01272425, -0.04459994,\n",
       "        0.00528481, -0.04831876,  0.02179734,  0.05695647,  0.0643986 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.word_vec('python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.020591</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>-0.009594</td>\n",
       "      <td>0.009289</td>\n",
       "      <td>-0.013258</td>\n",
       "      <td>0.001541</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.016136</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>0.040257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026155</td>\n",
       "      <td>0.010652</td>\n",
       "      <td>-0.000258</td>\n",
       "      <td>0.017933</td>\n",
       "      <td>-0.013131</td>\n",
       "      <td>-0.015923</td>\n",
       "      <td>-0.005616</td>\n",
       "      <td>0.023056</td>\n",
       "      <td>-0.005300</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.086399</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>-0.008081</td>\n",
       "      <td>-0.052468</td>\n",
       "      <td>-0.033288</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>0.008774</td>\n",
       "      <td>-0.027513</td>\n",
       "      <td>-0.006527</td>\n",
       "      <td>-0.010869</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132009</td>\n",
       "      <td>-0.037780</td>\n",
       "      <td>-0.134478</td>\n",
       "      <td>-0.067769</td>\n",
       "      <td>-0.103314</td>\n",
       "      <td>0.068596</td>\n",
       "      <td>0.199128</td>\n",
       "      <td>-0.144207</td>\n",
       "      <td>-0.002581</td>\n",
       "      <td>-0.035460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.075293</td>\n",
       "      <td>0.035324</td>\n",
       "      <td>0.021803</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>-0.008652</td>\n",
       "      <td>-0.045598</td>\n",
       "      <td>-0.025208</td>\n",
       "      <td>0.121888</td>\n",
       "      <td>0.012121</td>\n",
       "      <td>-0.037359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046711</td>\n",
       "      <td>-0.005466</td>\n",
       "      <td>0.020949</td>\n",
       "      <td>-0.109901</td>\n",
       "      <td>0.063326</td>\n",
       "      <td>0.039364</td>\n",
       "      <td>-0.111916</td>\n",
       "      <td>0.158293</td>\n",
       "      <td>-0.023077</td>\n",
       "      <td>0.149034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.011196</td>\n",
       "      <td>-0.103891</td>\n",
       "      <td>-0.043628</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>0.049972</td>\n",
       "      <td>-0.023560</td>\n",
       "      <td>-0.019589</td>\n",
       "      <td>0.028816</td>\n",
       "      <td>-0.025506</td>\n",
       "      <td>-0.017140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019384</td>\n",
       "      <td>0.029602</td>\n",
       "      <td>-0.051860</td>\n",
       "      <td>-0.029308</td>\n",
       "      <td>0.027239</td>\n",
       "      <td>-0.063819</td>\n",
       "      <td>-0.020493</td>\n",
       "      <td>-0.026045</td>\n",
       "      <td>-0.008431</td>\n",
       "      <td>-0.012771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012556</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>-0.011472</td>\n",
       "      <td>-0.003167</td>\n",
       "      <td>-0.012131</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.044781</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>-0.038432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072367</td>\n",
       "      <td>-0.046256</td>\n",
       "      <td>-0.095253</td>\n",
       "      <td>-0.023658</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.067213</td>\n",
       "      <td>0.046456</td>\n",
       "      <td>-0.026820</td>\n",
       "      <td>-0.033914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.020591  0.000633 -0.009594  0.009289 -0.013258  0.001541  0.010682   \n",
       "1 -0.086399 -0.001301 -0.008081 -0.052468 -0.033288  0.022888  0.008774   \n",
       "2  0.075293  0.035324  0.021803  0.011003 -0.008652 -0.045598 -0.025208   \n",
       "3 -0.011196 -0.103891 -0.043628  0.064636  0.049972 -0.023560 -0.019589   \n",
       "4 -0.012556 -0.009725  0.029292 -0.011472 -0.003167 -0.012131  0.016732   \n",
       "\n",
       "         7         8         9   ...        40        41        42        43  \\\n",
       "0  0.016136 -0.000757  0.040257  ... -0.026155  0.010652 -0.000258  0.017933   \n",
       "1 -0.027513 -0.006527 -0.010869  ... -0.132009 -0.037780 -0.134478 -0.067769   \n",
       "2  0.121888  0.012121 -0.037359  ... -0.046711 -0.005466  0.020949 -0.109901   \n",
       "3  0.028816 -0.025506 -0.017140  ... -0.019384  0.029602 -0.051860 -0.029308   \n",
       "4  0.044781 -0.005518 -0.038432  ... -0.072367 -0.046256 -0.095253 -0.023658   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0 -0.013131 -0.015923 -0.005616  0.023056 -0.005300  0.000123  \n",
       "1 -0.103314  0.068596  0.199128 -0.144207 -0.002581 -0.035460  \n",
       "2  0.063326  0.039364 -0.111916  0.158293 -0.023077  0.149034  \n",
       "3  0.027239 -0.063819 -0.020493 -0.026045 -0.008431 -0.012771  \n",
       "4  0.030297  0.031885  0.067213  0.046456 -0.026820 -0.033914  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_list = []\n",
    "for word in vocabulary:\n",
    "    seq_as_words = list(map(word_normalization, word.split()))\n",
    "    seq_avg_vector = average_word_vectors(model, seq_as_words, vocabulary)\n",
    "    data_list.append(seq_avg_vector)\n",
    "    \n",
    "data = np.vstack(data_list)\n",
    "df = pd.DataFrame(data=data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76172, 50)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x204991483a0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(\n",
    "    n_components=2,\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "result = pca.fit_transform(df)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(result[:, 0], result[:, 1])\n",
    "\n",
    "#for i, txt in enumerate(vocabulary):\n",
    "#    x, y = result[i, 0], result[i, 1]\n",
    "#    ax.annotate(txt, [x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "epoch_logger = EpochLogger()\n",
    "modelFastText = FastText(size=embedding_size, window=5, min_count=1,\n",
    "                    sentences=sentences_corpus,\n",
    "                    iter=10,\n",
    "                    workers = cores,\n",
    "                    callbacks=[epoch_logger])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4969088467906713"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.wmdistance('apple juice is realy good'.split(), 'oranges and apples are tasty'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5350884556236264"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelFastText.wv.wmdistance('apple juice is realy good'.split(), 'oranges and apples are tasty'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "df5 = pd.read_csv('hate_speech_twitter.csv')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "df5.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['rt', 'woman', 'complain', 'clean', 'house', 'amp', 'man', 'trash'], tags=['TWEET_0'])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "for index, row in df5.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(index)\n",
    "    text = row['tweet']\n",
    "    doc = nlp(text)  \n",
    "    doc_prepared = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    documents.append(TaggedDocument(doc_prepared, ['TWEET_%s' %index]))\n",
    "    \n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0 start\n",
      "Epoch #0 end\n",
      "Epoch #1 start\n",
      "Epoch #1 end\n",
      "Epoch #2 start\n",
      "Epoch #2 end\n",
      "Epoch #3 start\n",
      "Epoch #3 end\n",
      "Epoch #4 start\n",
      "Epoch #4 end\n",
      "Epoch #5 start\n",
      "Epoch #5 end\n",
      "Epoch #6 start\n",
      "Epoch #6 end\n",
      "Epoch #7 start\n",
      "Epoch #7 end\n",
      "Epoch #8 start\n",
      "Epoch #8 end\n",
      "Epoch #9 start\n",
      "Epoch #9 end\n"
     ]
    }
   ],
   "source": [
    "epoch_logger = EpochLogger()\n",
    "modelDoc2Vec = Doc2Vec(documents, size=embedding_size, window=5, min_count=1,\n",
    "                    iter=10,\n",
    "                    workers = cores,\n",
    "                    callbacks=[epoch_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03295977,  0.02218305, -0.01872486, -0.00047626, -0.00376105,\n",
       "        0.01739749,  0.03363158,  0.01445866,  0.01047152, -0.020078  ,\n",
       "       -0.01636694, -0.01998172, -0.00483465, -0.02766092,  0.01892491,\n",
       "       -0.01514195, -0.02061551,  0.03756815, -0.00869711, -0.00962509,\n",
       "       -0.02556566,  0.02854254,  0.02634089, -0.03745816,  0.00362752,\n",
       "       -0.00511962, -0.01271562,  0.02870048,  0.00750841,  0.04548075,\n",
       "        0.03161416, -0.00901211, -0.00375855, -0.02964339,  0.01864301,\n",
       "       -0.0274958 , -0.00680135, -0.02104076, -0.00300454,  0.01090271,\n",
       "       -0.01586366, -0.00653857,  0.00655571,  0.00138997, -0.01906078,\n",
       "        0.01602436,  0.00620148, -0.00609072, -0.00461576,  0.01281467],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDoc2Vec.infer_vector(['cos', 'tam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[0.005514013, 0.0113683175, -0.0035790561, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>[-0.0723158, 0.01798391, -0.05348623, 0.018083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>[-0.017072294, 6.9012975e-05, -0.0064990325, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>[0.004695186, -0.0067790104, -0.003710715, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>[-0.011278763, -0.009382275, 0.0050429427, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet  \\\n",
       "0      2  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                              vector  \n",
       "0  [0.005514013, 0.0113683175, -0.0035790561, -0....  \n",
       "1  [-0.0723158, 0.01798391, -0.05348623, 0.018083...  \n",
       "2  [-0.017072294, 6.9012975e-05, -0.0064990325, -...  \n",
       "3  [0.004695186, -0.0067790104, -0.003710715, -0....  \n",
       "4  [-0.011278763, -0.009382275, 0.0050429427, 0.0...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_tweets = []\n",
    "for idx in range(0,df5.shape[0]):\n",
    "    vectorized_tweets.append(modelDoc2Vec.docvecs['TWEET_%s' %idx])\n",
    "\n",
    "df5['vector'] = vectorized_tweets\n",
    "\n",
    "df5.to_csv(\"doc2vec_tweets.csv\", index=False, sep=',')\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train, test = train_test_split(df5, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train['class']\n",
    "train_x = pd.DataFrame(train['vector'].to_list())\n",
    "test_y = test['class']\n",
    "test_x = pd.DataFrame(test['vector'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='adam', activation='relu', random_state=0) # domyślne ustawienia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(random_state=0)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8106254203093477\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', clf.score(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nienawistna</th>\n",
       "      <th>wulgarna</th>\n",
       "      <th>neutralna</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nienawistna</th>\n",
       "      <td>3</td>\n",
       "      <td>382</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wulgarna</th>\n",
       "      <td>2</td>\n",
       "      <td>5478</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutralna</th>\n",
       "      <td>0</td>\n",
       "      <td>688</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              nienawistna   wulgarna   neutralna \n",
       "nienawistna              3        382          55\n",
       "wulgarna                 2       5478         281\n",
       "neutralna                0        688         546"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_prediction = clf.predict(test_x)\n",
    "\n",
    "cm = confusion_matrix(test_y, test_prediction)\n",
    "cm_labels = [\"nienawistna \", \"wulgarna \",\"neutralna \"]\n",
    "df_cm = pd.DataFrame(cm, index = cm_labels,\n",
    "                  columns = cm_labels)\n",
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie 6\n",
    "Issue z githuba gensim, w którym zawarta jest informacja o maksymalnej liczbie 10 000 tokenów w zdaniu [link](https://github.com/RaRe-Technologies/gensim/issues/2880)\n",
    "\n",
    "[Link](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py) do kodu źródłowego word2vec.py.\n",
    "\n",
    "Znajduje się tam zaimportowana stała MAX_WORDS_IN_BATCH (linia 212), która równa jest MAX_SENTENCE_LEN ([link](https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec_inner.pyx) plik word2vec_inner.pyx).\n",
    "\n",
    "MAX_SENTENCE_LEN z kolei jest równa 10 000 ([link](https://github.com/RaReTechnologies/gensim/blob/develop/gensim/models/word2vec_inner.pyx) - linia 31)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
